{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1971-02-05</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1971-02-08</td>\n",
       "      <td>100.839996</td>\n",
       "      <td>100.839996</td>\n",
       "      <td>100.839996</td>\n",
       "      <td>100.839996</td>\n",
       "      <td>100.839996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1971-02-09</td>\n",
       "      <td>100.760002</td>\n",
       "      <td>100.760002</td>\n",
       "      <td>100.760002</td>\n",
       "      <td>100.760002</td>\n",
       "      <td>100.760002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1971-02-10</td>\n",
       "      <td>100.690002</td>\n",
       "      <td>100.690002</td>\n",
       "      <td>100.690002</td>\n",
       "      <td>100.690002</td>\n",
       "      <td>100.690002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1971-02-11</td>\n",
       "      <td>101.449997</td>\n",
       "      <td>101.449997</td>\n",
       "      <td>101.449997</td>\n",
       "      <td>101.449997</td>\n",
       "      <td>101.449997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  1971-02-05  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "1  1971-02-08  100.839996  100.839996  100.839996  100.839996  100.839996   \n",
       "2  1971-02-09  100.760002  100.760002  100.760002  100.760002  100.760002   \n",
       "3  1971-02-10  100.690002  100.690002  100.690002  100.690002  100.690002   \n",
       "4  1971-02-11  101.449997  101.449997  101.449997  101.449997  101.449997   \n",
       "\n",
       "   Volume  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import CSV\n",
    "\n",
    "training_data = pd.read_csv('NASDAQ_Stock_Price_Train.csv')\n",
    "\n",
    "training_data.shape\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.839996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.760002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.690002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.449997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open\n",
       "0  100.000000\n",
       "1  100.839996\n",
       "2  100.760002\n",
       "3  100.690002\n",
       "4  101.449997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = training_data.iloc[:, 1:2]\n",
    "\n",
    "training_data.shape\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm = MinMaxScaler(feature_range = (0, 1))\n",
    "training_data = mm.fit_transform(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 1)\n",
      "(1257, 1)\n"
     ]
    }
   ],
   "source": [
    "# Getting the Inputs and Outputs\n",
    "\n",
    "x_train = training_data[0:1257]\n",
    "y_train = training_data[1:1258]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshape \n",
    "\n",
    "x_train = np.reshape(x_train, (1257, 1, 1))\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Keras Libraries and Packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "40/40 [==============================] - 3s 2ms/step - loss: 0.2667\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1773\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1131\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0693\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0405\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0226\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0119\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0059\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0028\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.2416e-04\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0817e-04\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.9337e-05\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.8674e-05\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.1282e-05\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 5.2222e-06\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2135e-06\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.8087e-06\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4291e-06\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3182e-06\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3911e-06\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4817e-06\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4650e-06\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.5404e-06\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.5011e-06\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4083e-06\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3456e-06\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.4613e-06\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 996us/step - loss: 2.4201e-06\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.4390e-06\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.4234e-06\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.5166e-06\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3546e-06\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4354e-06\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.5003e-06\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3590e-06\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.5023e-06\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.4294e-06\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4692e-06\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3934e-06\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.4252e-06\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3850e-06\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4144e-06\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.4176e-06\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3902e-06\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4202e-06\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3962e-06\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4399e-06\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3761e-06\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3515e-06\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4456e-06\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.2813e-06\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4131e-06\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.4026e-06\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3793e-06\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3117e-06\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4410e-06\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3768e-06\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4085e-06\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3767e-06\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3629e-06\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.5259e-06\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3793e-06\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4020e-06\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.2960e-06\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.4067e-06\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.4436e-06\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.4660e-06\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.4091e-06\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3724e-06\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3763e-06\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.4771e-06\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3678e-06\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3124e-06\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4083e-06\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3763e-06\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4443e-06\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3911e-06\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.4839e-06\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3316e-06\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3655e-06\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3629e-06\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3933e-06\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3459e-06\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.4168e-06\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 892us/step - loss: 2.3605e-06\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4136e-06\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3734e-06\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3582e-06\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3344e-06\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3579e-06\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3872e-06\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.2574e-06\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3454e-06\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3674e-06\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3592e-06\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3863e-06\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3438e-06\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4401e-06\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.2994e-06\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.4086e-06\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3854e-06\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3429e-06\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3243e-06\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3934e-06\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3821e-06\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3455e-06\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4483e-06\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4386e-06\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3663e-06\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.2622e-06\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.2919e-06\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3194e-06\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3299e-06\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2385e-06\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4593e-06\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3658e-06\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2541e-06\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2959e-06\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3131e-06\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2503e-06\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2989e-06\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2034e-06\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2737e-06\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2105e-06\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2735e-06\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2248e-06\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3073e-06\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3427e-06\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3420e-06\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2911e-06\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3404e-06\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2246e-06\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2824e-06\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2388e-06\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3482e-06\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.2693e-06\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3028e-06\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1322e-06\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2872e-06\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2860e-06\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3299e-06\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3338e-06\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3004e-06\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2690e-06\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1300e-06\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1541e-06\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2513e-06\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1653e-06\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2247e-06\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2267e-06\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.2386e-06\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.2067e-06\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1897e-06\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1333e-06\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1437e-06\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1311e-06\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1044e-06\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1388e-06\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1595e-06\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1596e-06\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.1278e-06\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1879e-06\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2272e-06\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0945e-06\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1353e-06\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1338e-06\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1048e-06\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1119e-06\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1586e-06\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0564e-06\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0373e-06\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0766e-06\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0499e-06\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0750e-06\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0113e-06\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1253e-06\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.0846e-06\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.9905e-06\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0587e-06\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0280e-06\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.9781e-06\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0663e-06\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1193e-06\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0714e-06\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0580e-06\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.0155e-06\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0181e-06\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.9773e-06\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.9060e-06\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.9375e-06\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 1.9980e-06\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.9965e-06\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0134e-06\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.8996e-06\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.8892e-06\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.8926e-06\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.9477e-06\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.8462e-06\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.9733e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2203d341d60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing the Model\n",
    "model = Sequential()\n",
    "\n",
    "#Adding the Input Layer and LSTM Layer\n",
    "model.add(LSTM(units = 4, activation = 'sigmoid', input_shape = (None, 1)))\n",
    "\n",
    "#Adding the Output Layer\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "#Compiling the Model\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "#Fitting the RNN to the Training Data\n",
    "model.fit(x_train, y_train, batch_size = 32, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9471.419922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9566.530273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9651.860352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9649.650391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9703.540039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open\n",
       "0  9471.419922\n",
       "1  9566.530273\n",
       "2  9651.860352\n",
       "3  9649.650391\n",
       "4  9703.540039"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the real stick of 2020 (June-December) i.e., importing the test dataset\n",
    "\n",
    "test_data = pd.read_csv('NASDAQ_Test.csv')\n",
    "real_stock_price = test_data.iloc[:, 1:2]\n",
    "real_stock_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5ed25d7be23d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreal_stock_price\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpredicted_stock_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    297\u001b[0m            [5, 6]])\n\u001b[0;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[1;34m(self, result, context)\u001b[0m\n\u001b[0;32m   1916\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_axes_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_ORDERS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m     \u001b[1;31m# ideally we would define this to avoid the getattr checks, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;31m# by definition an array here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Must pass 2-d input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input"
     ]
    }
   ],
   "source": [
    "#Getting the Predicted Stock Price of 2020 (June-December)\n",
    "\n",
    "inputs = real_stock_price\n",
    "input = mm.transform(inputs)\n",
    "input = np.reshape(inputs, (150, 1, 1))\n",
    "\n",
    "predicted_stock_price = model.predict(inputs)\n",
    "predicted_stock_price = mm.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price\n",
    "pd.DataFrame(predicted_stock_price).to_csv(\"predicted_stock_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the Results\n",
    "\n",
    "plt.plot(real_stock_price, color = 'red'. label = 'Real NASDAQ Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted NASDAQ Stock Price')\n",
    "plt.title('NASDAQ Stock Predicition')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('NASDAQ Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
